{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Mouhammad BAZZI\n",
    "\n",
    "Student Number: A20522180\n",
    "\n",
    "\n",
    "CS584- Fall 2022</br> <h1><br><b><font color='red'>Final Project</font></br></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **LIBRAIRIES IMPORTATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "#LIBRAIRIES IMPORTATION\n",
    "###############################################\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization, Activation, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adagrad, Adadelta, Adamax, Nadam\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "from  sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DATA IMPORTATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "#DATA IMPORTATION\n",
    "###############################################\n",
    "\n",
    "# We want to import the data from the data folder\n",
    "# in the data folder there is two folder one is Testing and another is Training\n",
    "# in each folder there is 4 other folder one is glioma_tumor,meningioma_tumor,no_tumor and pituitary_tumor\n",
    "# in each folder there is images of the tumor in a jpg format\n",
    "\n",
    "###############################################\n",
    "\n",
    "\n",
    "# We define some global variables\n",
    "CATEGORIES = [\"glioma_tumor\", \"meningioma_tumor\", \"no_tumor\", \"pituitary_tumor\"] # The different categories of the data\n",
    "TRAINING_DIR = \"H:/Desktop/Machine Learning/CS584-TumorsBrain/data/Training/\" #The path of the training data\n",
    "TESTING_DIR = \"H:/Desktop/Machine Learning/CS584-TumorsBrain/data/Testing/\" #The path of the testing data\n",
    "IMG_SIZE = 256 #The image is going to be resized to 256*256\n",
    "\n",
    "\n",
    "# We define two list one for the training data and another for the testing data\n",
    "training_data = []\n",
    "testing_data = []\n",
    "\n",
    "\n",
    "# This function is going to read the image and convert it into a numpy array\n",
    "# and then resize the image to IMG_SIZE*IMG_SIZE\n",
    "# and then append the image and the class number to the training_data list if the parameter train is true else append to the testing_data list\n",
    "def import_data(train = True):\n",
    "    for category in CATEGORIES:\n",
    "        if train:\n",
    "            path = os.path.join(TRAINING_DIR, category)\n",
    "        else:\n",
    "            path = os.path.join(TESTING_DIR, category)\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                if train:\n",
    "                    training_data.append([new_array, class_num])\n",
    "                else:\n",
    "                    testing_data.append([new_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "\n",
    "#We are going to call the import_data function to import the training data and testing data\n",
    "import_data(train = True)\n",
    "import_data(train = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DATA VISUALIZATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "#DATA VISUALIZATION\n",
    "###############################################\n",
    "\n",
    "# We are going to visualize the repartition of the data and plot some images from each class to see how the data looks like\n",
    "\n",
    "###############################################\n",
    "\n",
    "\n",
    "# This function is going to show the repartition of the images from each class\n",
    "# If the parameter train is true it will show the repartition of the training data else it will show the repartition of the testing data\n",
    "def visualize_data(train = True):\n",
    "    glioma_tumor = 0\n",
    "    meningioma_tumor = 0\n",
    "    no_tumor = 0\n",
    "    pituitary_tumor = 0\n",
    "    data_set = training_data if train else testing_data\n",
    "    for features, label in data_set:\n",
    "        if label == 0:\n",
    "            glioma_tumor += 1\n",
    "        elif label == 1:\n",
    "            meningioma_tumor += 1\n",
    "        elif label == 2:\n",
    "            no_tumor += 1\n",
    "        elif label == 3:\n",
    "            pituitary_tumor += 1\n",
    "    data_set_name = \"TRAINING\" if train else \"TESTING\"\n",
    "    print(data_set_name + \" DATA SET:\")\n",
    "    print(\"glioma_tumor: \", glioma_tumor)\n",
    "    print(\"meningioma_tumor: \", meningioma_tumor)\n",
    "    print(\"no_tumor: \", no_tumor)\n",
    "    print(\"pituitary_tumor: \", pituitary_tumor)\n",
    "    print(\"Total number of images: \", glioma_tumor + meningioma_tumor + no_tumor + pituitary_tumor)\n",
    "    plt.bar([\"glioma_tumor\", \"meningioma_tumor\", \"no_tumor\", \"pituitary_tumor\"], [glioma_tumor, meningioma_tumor, no_tumor, pituitary_tumor])\n",
    "    if train:\n",
    "        plt.title(\"Training Data\")\n",
    "    else:\n",
    "        plt.title(\"Testing Data\")\n",
    "    plt.show()\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "# We are going to call the visualize_data function to visualize the repartition of the training data and testing data\n",
    "visualize_data(train = True)\n",
    "visualize_data(train = False)\n",
    "\n",
    "\n",
    "# This function is going to show the images from each class\n",
    "# If the parameter train is true it will show the images from the training data else it will show the images from the testing data\n",
    "def show_image(train = True):\n",
    "    data_set = training_data if train else testing_data\n",
    "    data_set_name = \"TRAINING\" if train else \"TESTING\"\n",
    "    print(data_set_name + \" DATA SET:\")\n",
    "    #make a 4*4 grid and big size of each image\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "    #glioma_tumor\n",
    "    for features, label in data_set:\n",
    "        if label == 0:\n",
    "            axs[0, 0].imshow(features, cmap = \"gray\")\n",
    "            axs[0, 0].set_title(\"glioma_tumor\")\n",
    "            break\n",
    "    #meningioma_tumor\n",
    "    for features, label in data_set:\n",
    "        if label == 1:\n",
    "            axs[0, 1].imshow(features, cmap = \"gray\")\n",
    "            axs[0, 1].set_title(\"meningioma_tumor\")\n",
    "            break\n",
    "    #no_tumor\n",
    "    for features, label in data_set:\n",
    "        if label == 2:\n",
    "            axs[1, 0].imshow(features, cmap = \"gray\")\n",
    "            axs[1, 0].set_title(\"no_tumor\")\n",
    "            break\n",
    "    #pituitary_tumor\n",
    "    for features, label in data_set:\n",
    "        if label == 3:\n",
    "            axs[1, 1].imshow(features, cmap = \"gray\")\n",
    "            axs[1, 1].set_title(\"pituitary_tumor\")\n",
    "            break\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# We are going to call the show_image function to show the images from the training data and testing data\n",
    "show_image(train = True)\n",
    "show_image(train = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **OPTIONAL DATA PRE-PROCESSING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply a filter on each image to try to take advantage of the domain knowledge. We could use on of these 3 followings filters: Canny, Sobel and Laplacian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Canny filter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the canny filter to the training data and testing data\n",
    "def apply_canny(data_set, canny_threshold1 = 80, canny_threshold2 = 180):\n",
    "    for features, label in data_set:\n",
    "        features_before = features\n",
    "        features = cv2.Canny(features, canny_threshold1, canny_threshold2)\n",
    "    # Plot one image\n",
    "    plt.subplot(121),plt.imshow(features_before, cmap = \"gray\")\n",
    "    plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(122),plt.imshow(features, cmap = \"gray\")\n",
    "    plt.title('Edge Image (Canny)'), plt.xticks([]), plt.yticks([])\n",
    "    plt.show()\n",
    "    return data_set \n",
    "\n",
    "#Apply the canny filter to the training data and testing data\n",
    "training_data = apply_canny(training_data)\n",
    "testing_data = apply_canny(testing_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sobel Filter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the sobel filter to the training data and testing data\n",
    "def apply_sobel(data_set, kernel_size = 3):\n",
    "    for features, label in data_set:\n",
    "        features_before = features\n",
    "        features = cv2.Sobel(features, cv2.CV_64F, 1, 0, ksize=kernel_size)\n",
    "    # Plot one image\n",
    "    plt.subplot(121),plt.imshow(features_before, cmap = \"gray\")\n",
    "    plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(122),plt.imshow(features, cmap = \"gray\")\n",
    "    plt.title('Edge Image (Sobel)'), plt.xticks([]), plt.yticks([])\n",
    "    plt.show()\n",
    "    return data_set\n",
    "\n",
    "#Apply the sobel filter to the training data and testing data\n",
    "training_data = apply_sobel(training_data)\n",
    "testing_data = apply_sobel(testing_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Laplacian filter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the laplacian filter to the training data and testing data\n",
    "def apply_laplacian(data_set, kernel_size = 3):\n",
    "    for features, label in data_set:\n",
    "        features_before = features\n",
    "        features = cv2.Laplacian(features, cv2.CV_64F, ksize=kernel_size)\n",
    "    # Plot one image\n",
    "    plt.subplot(121),plt.imshow(features_before, cmap = \"gray\")\n",
    "    plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(122),plt.imshow(features, cmap = \"gray\")\n",
    "    plt.title('Edge Image (Laplacian)'), plt.xticks([]), plt.yticks([])\n",
    "    plt.show()\n",
    "    return data_set\n",
    "\n",
    "#Apply the laplacian filter to the training data and testing data\n",
    "training_data = apply_laplacian(training_data)\n",
    "testing_data = apply_laplacian(testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DATA PRE-PROCESSING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "#DATA PRE-PROCESSING\n",
    "###############################################\n",
    "\n",
    "# We are going to pre-process the data\n",
    "# To do that we will do the following steps:\n",
    "# 1- Shuffle the data\n",
    "# 2- Split the data into features and labels\n",
    "# 3- Split the training data into training data and validation data\n",
    "# 4- Normalize the data\n",
    "# 5- One-hot encode the labels\n",
    "\n",
    "################################################\n",
    "\n",
    "# We define some global variables that we are going to use in the pre-processing \n",
    "VAL_RATIO = 0.2 # The ratio of the validation data\n",
    "\n",
    "############################################################################################################\n",
    "# 1- Shuffle the training data and testing data\n",
    "\n",
    "random.shuffle(training_data)\n",
    "random.shuffle(testing_data)\n",
    "\n",
    "############################################################################################################\n",
    "# 2- Separate the features and the labels for the training data and testing data\n",
    "\n",
    "#We are going to separate the features and the labels for the training data\n",
    "x_train = []\n",
    "y_train = []\n",
    "for features, label in training_data:\n",
    "    x_train.append(features)\n",
    "    y_train.append(label)\n",
    "#We are going to separate the features and the labels for the testing data\n",
    "x_test = []\n",
    "y_test = []\n",
    "for features, label in testing_data:\n",
    "    x_test.append(features)\n",
    "    y_test.append(label)\n",
    "\n",
    "############################################################################################################\n",
    "# 3- Split the training data into training data and validation data\n",
    "\n",
    "val_size = int(len(x_train) * VAL_RATIO)\n",
    "x_val = x_train[:val_size]\n",
    "y_val = y_train[:val_size]\n",
    "x_train = x_train[val_size:]\n",
    "y_train = y_train[val_size:]\n",
    "\n",
    "############################################################################################################\n",
    "# 4&5- Normalize the training, validation and testing data and one-hot encode the labels\n",
    "\n",
    "#We are going to normalize the training data by dividing it by 255\n",
    "x_train = np.array(x_train) / 255\n",
    "x_val = np.array(x_val) / 255\n",
    "x_test = np.array(x_test) / 255\n",
    "\n",
    "#We are going to convert the labels to one-hot vectors\n",
    "y_train = to_categorical(y_train, num_classes = 4)\n",
    "y_val = to_categorical(y_val, num_classes = 4)\n",
    "y_test = to_categorical(y_test, num_classes = 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **FIRST MODEL: A SIMPLE NEURAL NETWORK**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Architecture & Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "#FIRST MODEL: A SIMPLE NEURAL NETWORK\n",
    "###############################################\n",
    "\n",
    "# We are going to build a simple neural network model\n",
    "\n",
    "############################################################################################################\n",
    "# 1- Build a simple neural network model & Compile the model\n",
    "\n",
    "# We are going to build a simple neural network model\n",
    "def build_and_compile_ann_model():\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape = (IMG_SIZE, IMG_SIZE, 1)))\n",
    "    model.add(Dense(256, activation = \"relu\"))\n",
    "    model.add(Dense(128, activation = \"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation = \"relu\"))\n",
    "    model.add(Dense(4, activation = \"softmax\"))\n",
    "    # We are going to compile the model\n",
    "    model.compile(optimizer = Adam(learning_rate = 0.0005), loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "model = build_and_compile_ann_model()\n",
    "model.summary()\n",
    "\n",
    "############################################################################################################\n",
    "# 2- Train the model\n",
    "\n",
    "# We are going to train the model\n",
    "history = model.fit(x_train, y_train, epochs = 1, batch_size = 32, validation_data = (x_val, y_val))\n",
    "\n",
    "############################################################################################################\n",
    "# 3- Plot the training and validation accuracy and loss\n",
    "\n",
    "# We are going to plot the training and validation accuracy and loss\n",
    "def plot_accuracy_loss(history):\n",
    "    plt.figure(figsize = (10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history[\"accuracy\"], label = \"Training Accuracy\")\n",
    "    plt.plot(history.history[\"val_accuracy\"], label = \"Validation Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history[\"loss\"], label = \"Training Loss\")\n",
    "    plt.plot(history.history[\"val_loss\"], label = \"Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Loss\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# We plot the training and validation accuracy and loss\n",
    "plot_accuracy_loss(history)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "90/90 [==============================] - 16s 130ms/step - loss: 1.8301 - accuracy: 0.4038 - val_loss: 1.7117 - val_accuracy: 0.3020\n",
      "Epoch 2/3\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 1.0819 - accuracy: 0.5422 - val_loss: 1.5443 - val_accuracy: 0.2843\n",
      "Epoch 3/3\n",
      "90/90 [==============================] - 10s 112ms/step - loss: 0.9995 - accuracy: 0.5735 - val_loss: 1.4011 - val_accuracy: 0.3934\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 1.4011 - accuracy: 0.3934\n",
      "Test Accuracy: 0.39340102672576904\n",
      "13/13 [==============================] - 1s 24ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# After tuning the hyperparameters we now train on our entire training data and evaluate on the testing data\n",
    "\n",
    "############################################################################################################\n",
    "# 4- Train the model on the entire training data\n",
    "\n",
    "# We compile again the model\n",
    "model = build_and_compile_ann_model()\n",
    "\n",
    "# We concatenate the training data and the validation data\n",
    "x_train_val = np.concatenate((x_train, x_val), axis = 0)\n",
    "y_train_val = np.concatenate((y_train, y_val), axis = 0)\n",
    "\n",
    "# We train the model on the entire training data\n",
    "history = model.fit(x_train_val, y_train_val, epochs = 3, batch_size = 32, verbose = 1)\n",
    "\n",
    "\n",
    "############################################################################################################\n",
    "# 5- Evaluate the model on the testing data\n",
    "\n",
    "# We evaluate the model on the testing data\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"Test Accuracy: \" + str(test_accuracy))\n",
    "\n",
    "# Confusion Matrix\n",
    "\n",
    "# We compute the predictions\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred, axis = 1)\n",
    "\n",
    "# We store the true labels\n",
    "y_true = np.argmax(y_test, axis = 1)\n",
    "\n",
    "# We compute the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# We plot the confusion matrix\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in CATEGORIES],\n",
    "                    columns = [i for i in CATEGORIES])\n",
    "plt.figure(figsize = (10, 7))\n",
    "sns.heatmap(df_cm, annot=True, fmt='g')\n",
    "plt.title('Confusion matrix')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **We save the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6- Save the model\n",
    "\n",
    "# We save the model\n",
    "model.save(\"model_ANN.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **SECOND MODEL: A CONVOLUTIONAL NEURAL NETWORK**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Architectue & Compilation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECOND MODEL: A CONVOLUTIONAL NEURAL NETWORK\n",
    "#####################################################\n",
    "\n",
    "#We are going to build a convolutional neural network model\n",
    "\n",
    "############################################################################################################\n",
    "# 1- Build a convolutional neural network model & Compile the model\n",
    "\n",
    "def build_and_compile_cnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation = \"relu\", input_shape = (IMG_SIZE, IMG_SIZE, 1)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation = \"relu\"))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation = \"relu\"))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(256, (3, 3), activation = \"relu\"))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(512, (3, 3), activation = \"relu\"))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation = \"relu\"))\n",
    "    model.add(Dense(32, activation = \"relu\"))\n",
    "    model.add(Dense(4, activation = \"softmax\"))\n",
    "    model.compile(optimizer = Adam(learning_rate = 0.0001), loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "model = build_and_compile_cnn_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load the images with ImageDataGenerator**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is to be used if we want to pre-process the images by applying a filter on them (Canny, Sobel or Laplacian filter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "# - If we want to apply a filter before ImageDataGenerator to the images we can do it here\n",
    "\n",
    "# Please select a number between 1 and 3:\n",
    "#   CANNY FILTER = 1\n",
    "#   SOBEL FILTER  = 2\n",
    "#   LAPLACIAN FILTER = 3\n",
    "#   NO FILTER = 0\n",
    "\n",
    "filter_number = 0\n",
    "\n",
    "#We create a function to apply a filter to the images\n",
    "def apply_filter(image, filter_number=0, canny_threshold1 = 80, canny_threshold2 = 180, sobel_ksize = 3, laplacian_ksize = 3):\n",
    "    if filter_number == 1:\n",
    "        image = cv2.Canny(image, canny_threshold1, canny_threshold2)\n",
    "    elif filter_number == 2:\n",
    "        image = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize = sobel_ksize)\n",
    "    elif filter_number == 3:\n",
    "        image = cv2.Laplacian(image, cv2.CV_64F, ksize = laplacian_ksize)\n",
    "    else:\n",
    "        image = image\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "# 2- Load the data using ImageDataGenerator\n",
    "\n",
    "# We define some global variables\n",
    "WITH_DATA_AUGMENTATION = False # Whether to use data augmentation or not\n",
    "CATEGORIES = [\"glioma_tumor\", \"meningioma_tumor\", \"no_tumor\", \"pituitary_tumor\"] # The categories\n",
    "TRAINING_DIR = \"H:/Desktop/Machine Learning/CS584-TumorsBrain/data/Training/\" # The training directory\n",
    "TESTING_DIR = \"H:/Desktop/Machine Learning/CS584-TumorsBrain/data/Testing/\" # The testing directory\n",
    "IMG_SIZE = 256 # The image size\n",
    "VAL_RATIO = 0.2 # The ratio of the validation data\n",
    "\n",
    "################################################\n",
    "\n",
    "\n",
    "# We are going to load the data using ImageDataGenerator (we define the generator)\n",
    "if WITH_DATA_AUGMENTATION:\n",
    "    train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                        rotation_range = 40,\n",
    "                                        width_shift_range = 0.2,\n",
    "                                        height_shift_range = 0.2,\n",
    "                                        shear_range = 0.2,\n",
    "                                        zoom_range = 0.2,\n",
    "                                        horizontal_flip = True,\n",
    "                                        fill_mode = \"nearest\",\n",
    "                                        validation_split = VAL_RATIO,\n",
    "                                        preprocessing_function = lambda x: apply_filter(x, filter_number))\n",
    "    train_val_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                            rotation_range = 40,\n",
    "                                            width_shift_range = 0.2,\n",
    "                                            height_shift_range = 0.2,\n",
    "                                            shear_range = 0.2,\n",
    "                                            zoom_range = 0.2,\n",
    "                                            horizontal_flip = True,\n",
    "                                            fill_mode = \"nearest\",\n",
    "                                            preprocessing_function = lambda x: apply_filter(x, filter_number))\n",
    "else:\n",
    "    train_datagen = ImageDataGenerator(rescale = 1./255, validation_split = VAL_RATIO, preprocessing_function = lambda x: apply_filter(x, filter_number))\n",
    "    train_val_datagen = ImageDataGenerator(rescale = 1./255, preprocessing_function = lambda x: apply_filter(x, filter_number))\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255, validation_split = VAL_RATIO, preprocessing_function = lambda x: apply_filter(x, filter_number))\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255, preprocessing_function = lambda x: apply_filter(x, filter_number))\n",
    "\n",
    "\n",
    "# We load the training data\n",
    "training_set = train_datagen.flow_from_directory(TRAINING_DIR\n",
    "                                                , target_size = (IMG_SIZE, IMG_SIZE)\n",
    "                                                , batch_size = 32\n",
    "                                                , class_mode = \"categorical\"\n",
    "                                                , subset = \"training\"\n",
    "                                                , shuffle = True\n",
    "                                                , seed = 42\n",
    "                                                , color_mode = \"grayscale\")\n",
    "\n",
    "# We load the validation data\n",
    "validation_set = val_datagen.flow_from_directory(TRAINING_DIR\n",
    "                                                , target_size = (IMG_SIZE, IMG_SIZE)\n",
    "                                                , batch_size = 32\n",
    "                                                , class_mode = \"categorical\"\n",
    "                                                , subset = \"validation\"\n",
    "                                                , shuffle = True\n",
    "                                                , seed = 42\n",
    "                                                , color_mode = \"grayscale\")\n",
    "\n",
    "# We load the testing data\n",
    "testing_set = test_datagen.flow_from_directory(TESTING_DIR\n",
    "                                                , target_size = (IMG_SIZE, IMG_SIZE)\n",
    "                                                , batch_size = 32\n",
    "                                                , class_mode = \"categorical\"\n",
    "                                                , shuffle = False\n",
    "                                                , seed = 42\n",
    "                                                , color_mode = \"grayscale\")\n",
    "\n",
    "# We load the training and validation data together\n",
    "training_val_set = train_val_datagen.flow_from_directory(TRAINING_DIR\n",
    "                                                        , target_size = (IMG_SIZE, IMG_SIZE)\n",
    "                                                        , batch_size = 32\n",
    "                                                        , class_mode = \"categorical\"\n",
    "                                                        , shuffle = True\n",
    "                                                        , seed = 42\n",
    "                                                        , color_mode = \"grayscale\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "# 3- Train the model & Plot the training and validation accuracy and loss\n",
    "\n",
    "# We build & compile the model\n",
    "model = build_and_compile_cnn_model()\n",
    "\n",
    "\n",
    "# We train the model\n",
    "step_per_epoch = training_set.n // training_set.batch_size\n",
    "validation_steps = validation_set.n // validation_set.batch_size\n",
    "history = model.fit(training_set, epochs = 2, steps_per_epoch = step_per_epoch, validation_data = validation_set, validation_steps = validation_steps, verbose = 1)\n",
    "\n",
    "# We plot the training and validation accuracy and loss\n",
    "\n",
    "# We define a function to plot the training and validation accuracy and loss\n",
    "def plot_accuracy_loss(history):\n",
    "    plt.figure(figsize = (15, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history[\"accuracy\"], label = \"Training Accuracy\")\n",
    "    plt.plot(history.history[\"val_accuracy\"], label = \"Validation Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history[\"loss\"], label = \"Training Loss\")\n",
    "    plt.plot(history.history[\"val_loss\"], label = \"Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Loss\")\n",
    "    plt.show()\n",
    "\n",
    "# We plot the training and validation accuracy and loss\n",
    "plot_accuracy_loss(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After tuning the hyperparameters we now train on our entire training data and evaluate on the testing data\n",
    "\n",
    "############################################################################################################\n",
    "# 4- Train the model on the entire training data\n",
    "\n",
    "# We compile again the model\n",
    "model = build_and_compile_cnn_model()\n",
    "\n",
    "# We train the model on the entire training data\n",
    "step_per_epoch = training_val_set.n // training_val_set.batch_size\n",
    "history = model.fit(training_val_set, epochs = 1, steps_per_epoch = step_per_epoch, verbose = 0)\n",
    "\n",
    "############################################################################################################\n",
    "# 5- Evaluate the model on the testing data\n",
    "\n",
    "# We evaluate the model on the testing data\n",
    "test_loss, test_accuracy = model.evaluate(testing_set, verbose = 0)\n",
    "print(\"Test Accuracy: \" + str(test_accuracy))\n",
    "\n",
    "# Confusion Matrix\n",
    "\n",
    "# We compute the predictions\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred, axis = 1)\n",
    "\n",
    "# We store the true labels\n",
    "y_true = np.argmax(y_test, axis = 1)\n",
    "\n",
    "# We compute the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# We plot the confusion matrix\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in CATEGORIES],\n",
    "                    columns = [i for i in CATEGORIES])\n",
    "plt.figure(figsize = (10, 7))\n",
    "sns.heatmap(df_cm, annot=True, fmt='g')\n",
    "plt.title('Confusion matrix')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Visualization of the activation filters**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to vizualize what are the output of each convolution layer for a given input to understand better what the Model has leraned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "# A- Visualize the output of each activation layer of the model for a given image\n",
    "\n",
    "# We define some global variables\n",
    "IMG_PATH = \"H:/Desktop/Machine Learning/CS584-TumorsBrain/data/Testing/glioma_tumor/image(1).jpg\" # The path of the image\n",
    "\n",
    "# We define a pre-processing function\n",
    "def preprocess_image(img_path = IMG_PATH):\n",
    "    img = image.load_img(img_path, target_size = (IMG_SIZE, IMG_SIZE), color_mode = \"grayscale\")\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis = 0)\n",
    "    img = img / 255\n",
    "    return img\n",
    "\n",
    "# We define a function to visualize the output of each activation layer of the model for a given image\n",
    "def visualize_activation_layers(img_path = IMG_PATH):\n",
    "    img = preprocess_image(img_path)\n",
    "\n",
    "    # We get the output of each activation layer of the model\n",
    "    layers_output = [layer.output for layer in model.layers if \"conv\" in layer.name]\n",
    "\n",
    "    # We create a model that will return these outputs, given the model input\n",
    "    activation_model = models.Model(inputs = model.input, outputs = layers_output)\n",
    "\n",
    "    # We run the model in predict mode\n",
    "    activations = activation_model.predict(img, verbose = 0)\n",
    "\n",
    "    # We get the names of the layers\n",
    "    layer_names = []\n",
    "    for layer in model.layers:\n",
    "        if \"conv\" in layer.name:\n",
    "            layer_names.append(layer.name)\n",
    "\n",
    "    # We display the feature maps\n",
    "    images_per_row = 16\n",
    "\n",
    "    for layer_name, layer_activation in zip(layer_names, activations):\n",
    "        n_features = layer_activation.shape[-1]\n",
    "        size = layer_activation.shape[1]\n",
    "        n_cols = n_features // images_per_row\n",
    "        display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "\n",
    "        for col in range(n_cols):\n",
    "            for row in range(images_per_row):\n",
    "                channel_image = layer_activation[0, :, :, col * images_per_row + row]\n",
    "                channel_image -= channel_image.mean()\n",
    "                channel_image /= channel_image.std()\n",
    "                channel_image *= 64\n",
    "                channel_image += 128\n",
    "                channel_image = np.clip(channel_image, 0, 255).astype(\"uint8\")\n",
    "                display_grid[col * size : (col + 1) * size, row * size : (row + 1) * size] = channel_image\n",
    "\n",
    "        scale = 1. / size\n",
    "        plt.figure(figsize = (scale * display_grid.shape[1], scale * display_grid.shape[0]))\n",
    "        plt.title(layer_name)\n",
    "        plt.grid(False)\n",
    "        plt.imshow(display_grid, aspect = \"auto\", cmap = \"viridis\")\n",
    "\n",
    "\n",
    "# We visualize the output of each activation layer of the model for a given image\n",
    "visualize_activation_layers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Visualization of the filters learned by the Convolutional layers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want now to visualize what input maximize the activation of a given filter, in another way we want to see which filter is learned. For that we will use Gradient Ascent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "# B- Visualization of the filters learned by the convolutional layers of the model using gradient ascent\n",
    "\n",
    "# We disable eager execution\n",
    "tf.compat.v1.disable_eager_execution() \n",
    "\n",
    "# We define a function that will deprocess the image\n",
    "def deprocess_image(x):\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.1\n",
    "\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    x *= 255\n",
    "    x = np.clip(x, 0, 255).astype(\"uint8\")\n",
    "    return x\n",
    "\n",
    "# We define a function to visualize the filters learned by the convolutional layers of the model using gradient ascent\n",
    "def visualize_filters():\n",
    "    # We get the output of each activation layer of the model\n",
    "    layers_output = [layer.output for layer in model.layers if \"conv\" in layer.name]\n",
    "\n",
    "    # We create a model that will return these outputs, given the model input\n",
    "    activation_model = models.Model(inputs = model.input, outputs = layers_output)\n",
    "\n",
    "    # We get the names of the layers\n",
    "    layer_names = []\n",
    "    for layer in model.layers:\n",
    "        if \"conv\" in layer.name:\n",
    "            layer_names.append(layer.name)\n",
    "\n",
    "    # We define a loss function that maximizes the activation of the nth filter of the layer considered\n",
    "    for layer_name in layer_names:\n",
    "        layer_output = activation_model.get_layer(layer_name).output\n",
    "        loss = K.mean(layer_output[:, :, :, 0])\n",
    "\n",
    "        # We compute the gradient of the input picture wrt this loss\n",
    "        grads = K.gradients(loss, model.input)[0]\n",
    "\n",
    "        # We normalize the gradient\n",
    "        grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
    "\n",
    "        # We define a Keras function that returns the loss and gradients given the input picture\n",
    "        iterate = K.function([model.input], [loss, grads])\n",
    "\n",
    "        # We start from a gray image with some noise\n",
    "        input_img_data = np.random.random((1, IMG_SIZE, IMG_SIZE, 1)) * 20 + 128.\n",
    "\n",
    "        # We run gradient ascent for 40 steps\n",
    "        step = 1.\n",
    "        for i in range(40):\n",
    "            loss_value, grads_value = iterate([input_img_data])\n",
    "            input_img_data += grads_value * step\n",
    "\n",
    "        # We decode the resulting input image\n",
    "        img = input_img_data[0]\n",
    "        img = deprocess_image(img)\n",
    "\n",
    "        # We display the result\n",
    "        plt.figure(figsize = (10, 10))\n",
    "        plt.title(layer_name)\n",
    "        plt.grid(False)\n",
    "        plt.imshow(img[:, :, 0], cmap = \"viridis\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# We visualize the filters learned by the convolutional layers of the model using gradient ascent\n",
    "visualize_filters()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Visualizing class activation heat map**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "# C- Visualization of the class activation heatmap of the model for a given image\n",
    "\n",
    "IMG_PATH = \"H:/Desktop/Machine Learning/CS584-TumorsBrain/data/Testing/meningioma_tumor/image(\" # The path of the image\n",
    "\n",
    "# We define a function that will preprocess the image\n",
    "def preprocess_image(img_path = IMG_PATH):\n",
    "    img = image.load_img(img_path, target_size = (IMG_SIZE, IMG_SIZE), color_mode = \"grayscale\")\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis = 0)\n",
    "    img = img / 255\n",
    "    return img\n",
    "\n",
    "# We define a function to visualize the class activation heatmap of the model for a given image\n",
    "def visualize_class_activation_heatmap(img_path = IMG_PATH):\n",
    "\n",
    "    # We preprocess the image\n",
    "    img = preprocess_image(img_path)\n",
    "\n",
    "    # We get the output of the last convolutional layer of the model\n",
    "    all_conv_layers = [layer for layer in model.layers if \"conv\" in layer.name]\n",
    "    last_conv_layer = all_conv_layers[-1]\n",
    "    last_conv_layer_output = last_conv_layer.output\n",
    "\n",
    "    # We get the output of the last fully connected layer of the model\n",
    "    all_fc_layers = [layer for layer in model.layers if \"dense\" in layer.name]\n",
    "    last_fc_layer = all_fc_layers[-1]\n",
    "    last_fc_layer_output = last_fc_layer.output\n",
    "\n",
    "    # We get the class activation heatmap\n",
    "    grads = K.gradients(last_fc_layer_output, last_conv_layer_output)[0]\n",
    "    pooled_grads = K.mean(grads, axis = (0, 1, 2))\n",
    "    iterate = K.function([model.input], [pooled_grads, last_conv_layer_output[0]])\n",
    "    pooled_grads_value, conv_layer_output_value = iterate([img])\n",
    "\n",
    "    for i in range(pooled_grads.shape[0]):\n",
    "        conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n",
    "\n",
    "    heatmap = np.mean(conv_layer_output_value, axis = -1)\n",
    "\n",
    "    # We post-process the class activation heatmap\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= np.max(heatmap)\n",
    "\n",
    "    # We display the original image\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # We do a figure composed of 2 subplots (1 for the original image and 1 for the superimposed heatmap)\n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    ax[0].imshow(img)\n",
    "    ax[0].set_title(\"Original Image\")\n",
    "    ax[0].axis(\"off\")\n",
    "\n",
    "    #plt.figure(figsize = (10, 10))\n",
    "    #plt.subplot(1, 2, 1)\n",
    "    #plt.title(\"Original image\")\n",
    "    #plt.grid(False)\n",
    "    #plt.imshow(img)\n",
    "\n",
    "    # We display the class activation heatmap\n",
    "    #plt.figure(figsize = (10, 10))\n",
    "    #plt.title(\"Class activation heatmap\")\n",
    "    #plt.grid(False)\n",
    "    #plt.imshow(heatmap, cmap = \"viridis\")\n",
    "    #plt.show()\n",
    "    \n",
    "    # We superimpose the class activation heatmap on the original image\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    superimposed_img = heatmap * 0.4 + img\n",
    "    superimposed_img = np.clip(superimposed_img, 0, 255).astype(np.uint8)\n",
    "    superimposed_img = cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB)\n",
    "    # We display the superimposed image\n",
    "    ax[1].imshow(superimposed_img)\n",
    "    ax[1].set_title(\"Class activation heatmap superimposed on the original image\")\n",
    "    ax[1].axis(\"off\")\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "# We visualize the class activation heatmap of the model for a given image\n",
    "for i in range(1, 100): # TODO: change the range\n",
    "    try:\n",
    "        visualize_class_activation_heatmap(IMG_PATH + str(i) + \").jpg\")\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **We save the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "# 6- We save the model\n",
    "\n",
    "# We save the model\n",
    "model.save(\"model_CNN.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
